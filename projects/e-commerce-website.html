<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Assistant - Lesego Makweya Portfolio</title>
    <link rel="stylesheet" href="../css/style.css"> </head>
<body>
    <header>
        <nav>
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="../index.html#projects">Projects</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <section class="project-detail">
            <h1>E-Commerce Website</h1>
            <p class="project-tagline">“Shop Smart, Shop Anywhere.”</p>

            <div class="project-links">
                <a href="https://github.com/lmakweya9/e-commerce-website" target="_blank" class="button">GitHub Repository</a>
            </div>

            <div class="project-overview">
                <h2>Project Overview</h2>
                <p>The E-Commerce Website is a digital platform designed to address the challenge of limited physical store access by enabling users to conveniently browse, select, and purchase products online, with the main goal of providing a seamless, efficient shopping experience that expands market reach and boosts sales.

</p>
                <img src="../img/[project-screenshot].png" alt="[Project Name] Screenshot">
            </div>

            <div class="project-problem">
                <h2>Problem Statement</h2>
                <p>The project addresses the challenge of limited convenience and accessibility in traditional retail by providing a 24/7 online shopping platform that overcomes geographical and time barriers, making it easier for customers to find and purchase products anytime, anywhere—an essential solution in today’s fast-paced, digital-driven marketplace.
</p>
            </div>

            <div class="project-approach">
                <h2>Methodology & Approach</h2>
                <p>The overall strategy involved first gathering and understanding relevant data to train the AI Assistant, including user queries and task workflows; then preprocessing and labeling the data to ensure quality and accuracy. Next, we developed and trained machine learning models using natural language processing techniques to interpret and respond effectively. After iterative testing and optimization, the model was integrated into the application for real-time interaction, followed by deployment on a scalable platform to ensure accessibility and performance. Finally, continuous monitoring and user feedback were used to refine the assistant’s accuracy and functionality.
</p>
                <ul>
                    <li>**Data Collection/Preparation:** Product data was gathered from supplier databases and publicly available catalogs, while user data was collected through sign-ups and interaction logs (with consent). The data was cleaned by removing duplicates, correcting formatting issues, standardizing categories, and ensuring consistency in product descriptions and images to create a reliable and searchable inventory.
</li>
                    <li>**Feature Engineering:** Yes, new features were created by deriving key attributes such as product popularity (based on views and purchases), user behavior metrics (like browsing time and click-through rate), and dynamic pricing indicators. These were generated using data aggregation, statistical analysis, and user interaction tracking to enhance recommendations, search relevance, and personalized shopping experiences.

</li>
                    <li>**Model Selection:** We selected collaborative filtering and content-based recommendation models to power product suggestions, as they effectively leverage user behavior and product attributes to deliver personalized results. These models were chosen for their balance of accuracy, scalability, and ability to improve user engagement and conversion rates on the e-commerce platform.

</li>
                    <li>**Training & Evaluation:** The recommendation models were trained using historical user interaction data, including views, clicks, and purchases. The training process involved optimizing for relevance and personalization using techniques like matrix factorization. Evaluation metrics included precision, recall, F1-score, and Mean Average Precision (MAP) to ensure accurate, useful recommendations that enhance the shopping experience.

</li>
                    <li>**Tools & Technologies:** The project used **Python** for backend development, **Django** as the web framework, and **MySQL** for database management. **HTML, CSS, and JavaScript** (with **React.js**) were used for the frontend. **Pandas**, **NumPy**, and **scikit-learn** supported data processing and machine learning tasks, while **Stripe API** handled secure online payments and **AWS** was used for deployment and hosting.

</li>
                </ul>
            </div>

            <div class="technical-deep-dive">
                <h2>Technical Deep Dive</h2>
                <p>A key algorithm implemented in the e-commerce website was **collaborative filtering** using **matrix factorization** for personalized product recommendations. This technique decomposes the user-item interaction matrix into lower-dimensional user and item feature matrices, allowing the system to predict which products a user might like based on patterns from similar users. One challenge was handling sparse data due to new users or products (cold start problem), which we addressed by combining collaborative filtering with **content-based filtering**—leveraging product attributes like category, price, and brand to make initial suggestions. This hybrid approach significantly improved recommendation accuracy and user satisfaction.

</p>
                <pre><code>

                </code></pre>
                <p>Ensure content originality and integrity with a powerful detection system that leverages advanced machine learning and natural language processing (NLP) techniques. This solution scans a vast range of sources—including academic papers, websites, and published books—to identify similarities and potential plagiarism. Ideal for educators, students, and content creators, it delivers fast, accurate reports to help maintain credibility and trust.</p>
            </div>
        </section>
    </main>

    <footer>
        <p>&copy; 2025 Lesego Makweya. All rights reserved.</p>
    </footer>

    <script src="../js/script.js"></script>
</body>
</html>